---
title: "04 - Bayesian Statistics"
date: "2025-05-02"
---

Mini Project 4: Bayesian Statistics

```{r}
library(tidyverse)
```


```{r}
# non-informative prior for this probability.
## trying to get a mean of 3 and a probability
## that lambda is less than 2 equal to 0.02

ps <- seq(0, 1, length.out = 1000)

noninformative_alpha <- 1
noninformative_beta <- 1

noninformative_prior1 <- dbeta(ps,
                              noninformative_alpha, noninformative_beta)

```

```{r}
# an informative prior based on a clay-court match the two played in the previous year. In that match, Nadal won 46 out of 66 points on his own serve. The standard error of this estimate is 0.05657.
target_mean <- 46/66

alphas <- seq(0.1, 60, length.out = 500)
betas <- (1-target_mean)*alphas/target_mean

param_df <- tibble(alphas, betas)
param_df <- param_df |> mutate(vars = (alphas*betas)/((alphas+betas)^2*(alphas+betas+1)))


target_var <- (.05657)^2

param_df <- param_df |> mutate(dist_to_target = abs(vars - target_var))
param_df

param_df |> filter(dist_to_target == min(dist_to_target))
```

```{r}
# an informative prior based on a sports announcer, who claims that they think Nadal wins about 75% of the points on his serve against Djokovic. They are also “almost sure” that Nadal wins no less than 70% of his points on serve against Djokovic.
## trying to get a mean of 3 and a probability
## that lambda is less than 2 equal to 0.02
alphas <- seq(0.01, 100, length.out = 2000) 
ks <- alphas * (1 - 0.75) / 0.75 

target_prob <- .02
prob_less_point7 <- pgamma(.7, alphas, ks)

tibble(alphas, ks, prob_less_point7) |>
  mutate(close_to_target = abs(prob_less_point7 - target_prob)) |>
  filter(close_to_target == min(close_to_target))
```

```{r}
library(tidyverse)
ps <- seq(0, 1, length.out = 1000)

noninformative_alpha <- 1 ## CHANGE THIS TO YOUR ALPHA
noninformative_beta <- 1  ## CHANGE THIS TO YOUR BETA

informative_alpha1 <- 45.36
informative_beta1 <- 19.72

noninformative_prior <- dbeta(ps, noninformative_alpha,
                           noninformative_beta)
informative_prior1 <- dbeta(ps,
                              informative_alpha1, informative_beta1)

## CHANGE THESE
informative_alpha_prior2 <- 3.66
informative_beta_prior2 <- 1.22
informative_prior2 <- dbeta(ps, informative_alpha_prior2,
                          informative_beta_prior2)


plot_df <- tibble(ps, noninformative_prior, informative_prior1,
                     informative_prior2) |>
  pivot_longer(2:4, names_to = "distribution", values_to = "density") |>
  separate(distribution, into = c("prior_type", "distribution"))

ggplot(data = plot_df, aes(x = ps, y = density, colour = prior_type,
                           linetype = distribution)) +
  geom_line() +
  scale_colour_viridis_d(end = 0.9) +
  theme_minimal() +
  labs(x = "p")
```
```{r}
# Non-informative posterior
noninformative_alpha_post <- 1 + 56
noninformative_beta_post <- 1 + 28
mean1 <- noninformative_alpha_post / (noninformative_alpha_post + noninformative_beta_post)
ci1 <- qbeta(c(0.05, 0.95), noninformative_alpha_post, noninformative_beta_post)

cat("1. Non-informative Posterior:\n")
cat("   Mean:", mean1, "\n")
cat("   90% Credible Interval:", ci1[1], "-", ci1[2], "\n\n")

# Informative posterior from previous match
alphapost1 <- 45.36 + 56
betapost1 <- 19.72 + 28
mean2 <- alphapost1 / (alphapost1 + betapost1)
ci2 <- qbeta(c(0.05, 0.95), alphapost1, betapost1)

cat("2. Informative Posterior (Match Data):\n")
cat("   Mean:", mean2, "\n")
cat("   90% Credible Interval:", ci2[1], "-", ci2[2], "\n\n")

# Informative posterior from sports announcer
alphapost2 <- 3.66 + 56
betapost2 <- 1.22 + 28
mean3 <- alphapost2 / (alphapost2 + betapost2)
ci3 <- qbeta(c(0.05, 0.95), alphapost2, betapost2)

cat("3. Informative Posterior (Announcer's Belief):\n")
cat("   Mean:", mean3, "\n")
cat("   90% Credible Interval:", ci3[1], "-", ci3[2], "\n")

```

```{r}
library(tidyverse)
ps <- seq(0, 1, length.out = 1000)

#noninformative posterior
noninformative_post <- dbeta(ps, noninformative_alpha_post,
                           noninformative_beta_post)
#informative posterior 1
informative_post1 <- dbeta(ps,
                              alphapost1, betapost1)

#informative posterior 2
informative_post2 <- dbeta(ps, alphapost2,
                          betapost2)

#plot
plot_df <- tibble(ps, noninformative_post, informative_post1,
                     informative_post2) |>
  pivot_longer(2:4, names_to = "distribution", values_to = "density") |>
  separate(distribution, into = c("prior_type", "distribution"))

ggplot(data = plot_df, aes(x = ps, y = density, colour = prior_type,
                           linetype = distribution)) +
  geom_line() +
  scale_colour_viridis_d(end = 0.9) +
  theme_minimal() +
  labs(x = "p")
```

Report:

*In this project, we are looking how three different priors do in representing the distribution of the probability of Nadal winning a point on his serve when playing on clay courts against Djokovic. To answer this, I graphed the three priors and then updated the priors with data from the 2020 French Open. I will then explore these distributions as well as their 90% confidence intervals and means. 

*To create the noninformative prior, I just used a beta distribution with alpha and beta equal to 1. To create the prior for the observed data, I created a target mean of the probability from the data and ran through different alphas and betas to get yield a mean of .4 and a vairaince closest to the target. 
To create the prior for based on the sports announcer prediction we used their probability they claim in correct and run through combinations of alpha and ks to get the probability. Since they are "almost sure" that Nadal wins no less than 70% of the points I used a target_prob of .02 because it's not likely, but not impossible. I used a gamma distribution to find this probability.For these priors, we made the assumptions that the matches were all independent, so Nadal doing well or not well before didn't affect how he did at the 2020 French Open.

*Graphs and intervals are above.

*All of the posteriors are a bit different because their priors were all different and we added the same values to each of them. If I were to pick one, I would pick the post1 which is based on the prior of the other observed match. The distribution did not move too much from it's prior and has the narrowest interval. Since the distribution didn't move form the prior to the posterior, the variance will be lower than the other two posteriors. 

*In this mini-project, I found, with some difference depending on the prior used, the probability of Nadal winning a point when he serves againt Djokovic on clay courts is between around .58 and .74.


