---
title: "Reflection"
date: "2025-05-06"
---
Reflection of Mini Projects



All of these mini project, as designed, recap the main topics learned in this class. In the first mini project we had to construct sampling distributions from various distributions which set a base understanding for a lot of what we did throughout the semester. Understanding these distributions made more complex uses of distributions much easier. Writing the 'meaningful story' in the second mini project made me fully understand a lot of the vocabulary which came up throughout the rest of the semester. Also, it was nice to be challenged in an atypical way for a statistics/math class. In mini project three, we had to consider a 'large enough' sample which was an assumption we made throughout the semester, so to have to implement this made it more clear what the consequence was of not using a big enough sample. Mini project four used our prior knowledge of probability distributions and built on it by using them as priors to get a posterior distribution. The fifth and final mini project was all about the use of p-values, which we used throughout the semester. We would often test using r code to see if something was significant and either reject or don't reject. But in this article that we read they argued maybe this isn't the best practice in statistics. This was a new idea that I hadn't thought about before since we relied on them so heavily from STAT 113 all the way to this class. In three of the mini projects we used R code which helped doing homework assignments as well as for the exams when we would write an answer in R code. Overall, the Mini Projects were a great way to better understand the content in the chapter, which we often used in a later chapter. Much of the course material built on itself, so having the mini projects was a good way to practice the topic without having an exam or quiz on it. 

Mini project two was essential to get a stronger understanding of some of the vocab of the things we used in most of the mini projects. Understanding distributions, variances, statistics, as well as some of the other words we had to incorporate, were used directly in mini project 1 where we had to create a sampling distribution of the sample minimum and maximum as well as in mini project four where we had a prior and posterior distribution. I was originally going to say maybe this should be the first mini project, but I actually liked that we had to use sampling distributions without diving super deep into the definition of it, and then later going back and really understanding the meaning of what a sampling distribution is. The variance came up quite a bit throughout the course and in the mini projects, especially in mini project four. One of the questions we had to answer was 'Why do you think one posterior has a lower variance than the other two?'. In mini project four, we used prior distributions to explore posterior distributions for tennis data. This built on mini project one were we were creating these distributions. Without completing mini project one and two, it would not have been as clear what the prior and posterior distributions were. The third and fourth mini projects tie in closely since we used intervals for both. In the third we used confidence intervals and in the fourth we used credible intervals. These are closely linked, the difference being confidence intervals are used for frequentest statistics and credible intervals are used for Bayesian statistics. Going off of these two mini projects, in mini project five we read about how p values and confidence intervals shouldn't be a part of statistics. It is interesting to think about how two out of our five projects relied on these intervals that people are calling arbitrary and argue they shouldn't be used in practice. In the three computational mini projects (1,3,4) we furthered our skills in R Studio; creating visuals, computing p-values and confidence intervals, and simulating distributions. I liked that two of the mini projects were unusual assignments for a math/stat course in that we had to be creative and be thoughtful of our answers. All of these projects build nicely on each other, making it necessary to understand the prior project before being successful on the next, whether this be in content or creating the code or to write about the topic. 

I liked how most of these mini projects made us revisit the topics while having to think a little deeper about the topic. We had often had to do what we were learning from scratch, starting with a distribution and then applying some of the concepts, ideas, and practices we learned throughout the semester. Being able to write code ourselves and make visuals that allowed us to further understand the topics was extremely helpful in understanding the topic while making the tests seem more simple because we had to get so familiar with the topic while completing the mini projects. 

The main takeaway from mini project 1 was that we got better at deriving the expected value and standard error of $Y_{min}$ and $Y_{max}$ from a pdf and comparing with various distributions. One thing to notice is that since the normal distribution is symmetrical, their $SE_{Y_{min}}$ and $SE_{Y_{max}}$ are the same. This is also true for uniform distribution. The biggest takeaway from mini project 2 was simply a better understanding of basic vocabulary we use in the class. I thought I knew what each meant, but having to use it in a story made me realize I wasn't quite as sure of the exact use. So completing this project was extremely beneficial in learning key concepts. 
In mini project 3, the main takeaway was that coverage rates get higher as sample size $n$ increases and average width decreases as n increases. This makes sense that with a large sample size the coverage rate gets very close to our 90% confidence interval, showing the normal approximation holds. And the average width of the confidence interval shrinks because we can more precisely gauge where the interval will be. Also, this mini project provided us with practice on how to determine if a sample is 'large enough' which was an assumption we made throughout the semester. 
I enjoyed doing mini project 4 because it was about Bayesian statistics, which I had never really encountered before. Doing this mini project with a real life example where we visualized the priors and posteriors made me better understand Bayesian statistics compared to frequentest statistics. The big takeaway from this was that usually, the best model to pick is one where the posterior doesn't change too much from the prior, showing it was a good prior. 
The main takeaway from mini project 5 is that statistics is evolving and changing, with p-values and confidence intervals being the example in this article. It tells us how we need to have critical thinking while doing statistics, not just running models for the sake of getting a low p value. It is especially important with emerging technology to have what they call 'statistical thoughtfulness' when doing any type of data analysis, whether it being for a statistics class, doing statistical research, or doing research in science where you are using data. 
