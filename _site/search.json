[
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/03-ConfidenceIntervals/index.html",
    "href": "posts/03-ConfidenceIntervals/index.html",
    "title": "03 - Confidence Intervals",
    "section": "",
    "text": "Mini Project 3: Confidence Intervals\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nn = 5000 p = .5\n\nn &lt;- 5000   # sample size\np &lt;- 0.5  # population proportion\nalpha &lt;- .1\n\ngenerate_samp_prop &lt;- function(n,p){\n  x &lt;- rbinom(1, n, p) # randomly generate number of successes for the sample\n  \n  ## number of successes divided by sample size\n  phat &lt;- x / n\n  \n  #create lower and upper bound with 90% CI\n   lb &lt;- phat - 1.645 *sqrt(phat*(1-phat)/n)\n   ub &lt;- phat + 1.645 *sqrt(phat*(1-phat)/n)\n  \n\n  prop_df &lt;- tibble(phat,lb,ub)\n  return(prop_df)\n}\n\ngenerate_samp_prop(n,p)\n\n# A tibble: 1 × 3\n   phat    lb    ub\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 0.501 0.489 0.513\n\n#How many CI's we want\nn_sim &lt;- 1000\n\nprop_ci_df &lt;- map(1:n_sim, \\(i) generate_samp_prop(n,p)) |&gt; \n  bind_rows()\nprop_ci_df\n\n# A tibble: 1,000 × 3\n    phat    lb    ub\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 0.499 0.487 0.511\n 2 0.500 0.488 0.511\n 3 0.504 0.492 0.515\n 4 0.492 0.480 0.504\n 5 0.511 0.499 0.523\n 6 0.514 0.503 0.526\n 7 0.510 0.498 0.521\n 8 0.503 0.491 0.515\n 9 0.498 0.487 0.510\n10 0.499 0.488 0.511\n# ℹ 990 more rows\n\nprop_ci_df &lt;- prop_ci_df |&gt; mutate(ci_width = ub - lb,\n                                   ci_cover_ind = if_else(p &gt; lb & p &lt; ub,\n                                                          true = 1, \n                                                          false = 0))\nprop_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1    0.0233         0.905\n\n\nn = 100 p=.5\n\nn &lt;- 100   # sample size\np &lt;- 0.5  # population proportion\nalpha &lt;- .1\n\ngenerate_samp_prop &lt;- function(n,p){\n  x &lt;- rbinom(1, n, p) # randomly generate number of successes for the sample\n  \n  ## number of successes divided by sample size\n  phat &lt;- x / n\n  \n  #create lower and upper bound with 90% CI\n  lb &lt;- phat - 1.645 *sqrt(phat*(1-phat)/n)\n  ub &lt;- phat + 1.645 *sqrt(phat*(1-phat)/n)\n  \n  prop_df &lt;- tibble(phat,lb,ub)\n  return(prop_df)\n}\n\ngenerate_samp_prop(n,p)\n\n# A tibble: 1 × 3\n   phat    lb    ub\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1   0.5 0.418 0.582\n\n#How many CI's we want\nn_sim &lt;- 1000\n\nprop_ci_df &lt;- map(1:n_sim, \\(i) generate_samp_prop(n,p)) |&gt; \n  bind_rows()\nprop_ci_df\n\n# A tibble: 1,000 × 3\n    phat    lb    ub\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.56 0.478 0.642\n 2  0.52 0.438 0.602\n 3  0.49 0.408 0.572\n 4  0.48 0.398 0.562\n 5  0.5  0.418 0.582\n 6  0.46 0.378 0.542\n 7  0.5  0.418 0.582\n 8  0.59 0.509 0.671\n 9  0.5  0.418 0.582\n10  0.55 0.468 0.632\n# ℹ 990 more rows\n\nprop_ci_df &lt;- prop_ci_df |&gt; mutate(ci_width = ub - lb,\n                                   ci_cover_ind = if_else(p &gt; lb & p &lt; ub,\n                                                          true = 1, \n                                                          false = 0))\nprop_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.164         0.901\n\n\nn = 5 p = .5\n\nn &lt;- 5   # sample size\np &lt;- 0.5  # population proportion\nalpha &lt;- .1\n\ngenerate_samp_prop &lt;- function(n,p){\n  x &lt;- rbinom(1, n, p) # randomly generate number of successes for the sample\n  \n  ## number of successes divided by sample size\n  phat &lt;- x / n\n  \n  #create lower and upper bound with 90% CI\n   lb &lt;- phat - 1.645 *sqrt(phat*(1-phat)/n)\n   ub &lt;- phat + 1.645 *sqrt(phat*(1-phat)/n)\n  \n  prop_df &lt;- tibble(phat,lb,ub)\n  return(prop_df)\n}\n\ngenerate_samp_prop(n,p)\n\n# A tibble: 1 × 3\n   phat    lb    ub\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1   0.6 0.240 0.960\n\n#How many CI's we want\nn_sim &lt;- 1000\n\nprop_ci_df &lt;- map(1:n_sim, \\(i) generate_samp_prop(n,p)) |&gt; \n  bind_rows()\nprop_ci_df\n\n# A tibble: 1,000 × 3\n    phat     lb    ub\n   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1   0.6 0.240  0.960\n 2   0.8 0.506  1.09 \n 3   0.8 0.506  1.09 \n 4   0.6 0.240  0.960\n 5   0.4 0.0396 0.760\n 6   0.8 0.506  1.09 \n 7   0.6 0.240  0.960\n 8   0.8 0.506  1.09 \n 9   0.6 0.240  0.960\n10   0.4 0.0396 0.760\n# ℹ 990 more rows\n\nprop_ci_df &lt;- prop_ci_df |&gt; mutate(ci_width = ub - lb,\n                                   ci_cover_ind = if_else(p &gt; lb & p &lt; ub,\n                                                          true = 1, \n                                                          false = 0))\nprop_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.630         0.603\n\n\nn = 5000 p = .9\n\nn &lt;- 5000   # sample size\np &lt;- 0.9  # population proportion\nalpha &lt;- .1\n\ngenerate_samp_prop &lt;- function(n,p){\n  x &lt;- rbinom(1, n, p) # randomly generate number of successes for the sample\n  \n  ## number of successes divided by sample size\n  phat &lt;- x / n\n  \n  #create lower and upper bound with 90% CI\n  lb &lt;- phat - 1.645 *sqrt(phat*(1-phat)/n)\n  ub &lt;- phat + 1.645 *sqrt(phat*(1-phat)/n)\n  \n  \n  prop_df &lt;- tibble(phat,lb,ub)\n  return(prop_df)\n}\n\ngenerate_samp_prop(n,p)\n\n# A tibble: 1 × 3\n   phat    lb    ub\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 0.905 0.898 0.912\n\n#How many CI's we want\nn_sim &lt;- 1000\n\nprop_ci_df &lt;- map(1:n_sim, \\(i) generate_samp_prop(n,p)) |&gt; \n  bind_rows()\nprop_ci_df\n\n# A tibble: 1,000 × 3\n    phat    lb    ub\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 0.901 0.894 0.908\n 2 0.897 0.890 0.904\n 3 0.892 0.885 0.899\n 4 0.9   0.893 0.907\n 5 0.896 0.889 0.903\n 6 0.896 0.889 0.903\n 7 0.899 0.892 0.906\n 8 0.896 0.889 0.903\n 9 0.896 0.888 0.903\n10 0.900 0.893 0.907\n# ℹ 990 more rows\n\nprop_ci_df &lt;- prop_ci_df |&gt; mutate(ci_width = ub - lb,\n                                   ci_cover_ind = if_else(p &gt; lb & p &lt; ub,\n                                                          true = 1, \n                                                          false = 0))\nprop_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1    0.0139           0.9\n\n\nn = 100 p = .9\n\nn &lt;- 100   # sample size\np &lt;- .9  # population proportion\nalpha &lt;- .1\n\ngenerate_samp_prop &lt;- function(n,p){\n  x &lt;- rbinom(1, n, p) # randomly generate number of successes for the sample\n  \n  ## number of successes divided by sample size\n  phat &lt;- x / n\n  \n  #create lower and upper bound with 90% CI\n   lb &lt;- phat - 1.645 *sqrt(phat*(1-phat)/n)\n   ub &lt;- phat + 1.645 *sqrt(phat*(1-phat)/n)\n  \n\n  prop_df &lt;- tibble(phat,lb,ub)\n  return(prop_df)\n}\n\ngenerate_samp_prop(n,p)\n\n# A tibble: 1 × 3\n   phat    lb    ub\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  0.87 0.815 0.925\n\n#How many CI's we want\nn_sim &lt;- 1000\n\nprop_ci_df &lt;- map(1:n_sim, \\(i) generate_samp_prop(n,p)) |&gt; \n  bind_rows()\nprop_ci_df\n\n# A tibble: 1,000 × 3\n    phat    lb    ub\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.94 0.901 0.979\n 2  0.93 0.888 0.972\n 3  0.91 0.863 0.957\n 4  0.89 0.839 0.941\n 5  0.91 0.863 0.957\n 6  0.91 0.863 0.957\n 7  0.9  0.851 0.949\n 8  0.92 0.875 0.965\n 9  0.92 0.875 0.965\n10  0.88 0.827 0.933\n# ℹ 990 more rows\n\nprop_ci_df &lt;- prop_ci_df |&gt; mutate(ci_width = ub - lb,\n                                   ci_cover_ind = if_else(p &gt; lb & p &lt; ub,\n                                                          true = 1, \n                                                          false = 0))\nprop_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1    0.0974         0.853\n\n\nn = 5 p = .9\n\nn &lt;- 5   # sample size\np &lt;- 0.9  # population proportion\nalpha &lt;- .1\n\ngenerate_samp_prop &lt;- function(n,p){\n  x &lt;- rbinom(1, n, p) # randomly generate number of successes for the sample\n  \n  ## number of successes divided by sample size\n  phat &lt;- x / n\n  \n  #create lower and upper bound with 90% CI\n  lb &lt;- phat - 1.645 *sqrt(phat*(1-phat)/n)\n  ub &lt;- phat + 1.645 *sqrt(phat*(1-phat)/n)\n  \n  \n  prop_df &lt;- tibble(phat,lb,ub)\n  return(prop_df)\n}\n\ngenerate_samp_prop(n,p)\n\n# A tibble: 1 × 3\n   phat    lb    ub\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     1     1\n\n#How many CI's we want\nn_sim &lt;- 1000\n\nprop_ci_df &lt;- map(1:n_sim, \\(i) generate_samp_prop(n,p)) |&gt; \n  bind_rows()\nprop_ci_df\n\n# A tibble: 1,000 × 3\n    phat    lb    ub\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1   1   1     1    \n 2   0.8 0.506 1.09 \n 3   1   1     1    \n 4   1   1     1    \n 5   0.8 0.506 1.09 \n 6   1   1     1    \n 7   0.8 0.506 1.09 \n 8   0.6 0.240 0.960\n 9   1   1     1    \n10   1   1     1    \n# ℹ 990 more rows\n\nprop_ci_df &lt;- prop_ci_df |&gt; mutate(ci_width = ub - lb,\n                                   ci_cover_ind = if_else(p &gt; lb & p &lt; ub,\n                                                          true = 1, \n                                                          false = 0))\nprop_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.264         0.418\n\n\n\\((n = 5000, p = .9):\\)\n\\(np = 5000(.9) = 4500 &gt; 10\\): Assumption holds.\n\\(n(1-p) = 5000(1-.9) = 500 &gt; 10\\): Assumption holds.\n\\((n = 100, p = .9):\\)\n\\(np = 100(.9) = 90 &gt;10\\): Assumption holds.\n\\(n(1-p) = 100(1-.9) = 10 = 10\\): Assumption is equal to 10, so doesn’t hold.\n\\((n = 5, p = .9):\\)\n\\(np = 5(.9) = 4.5 &lt; 10\\): Assumption doesn’t hold.\n\\(n(1-p) = 5(1-.9) = .5 &lt; 10\\): Assumption doesn’t hold.\n\\((n = 5000, p = .5):\\)\n\\(np = 5000(.5) = 2500 &gt; 10\\): Assumption holds.\n\\(n(1-p) = 5000(1-.5) = 2500 &gt; 10\\): Assumption holds.\n\\((n = 100, p = .5):\\)\n\\(np = 100(.5) = 50 &gt;10\\): Assumption holds.\n\\(n(1-p) = 100(1-.5) = 50 &gt; 10\\): Assumption holds.\n\\((n = 5, p = .5):\\)\n\\(np = 5(.9) = 2.5 &lt; 5\\): Assumption doesn’t hold.\n\\(n(1-p) = 5(1-.5) = 5 &lt; 10\\): Assumption doesn’t hold.\n\nTable of Results\n\n\n\n\n\n\n\n\n\n\n\n\\(n = 5\\)\n\\(n = 100\\)\n\\(n = 5000\\)\n\n\n\n\n\\(p = .9\\)\nCoverage Rate\n.378\n.872\n.895\n\n\n\\(p = .5\\)\nCoverage Rate\n.631\n.915\n.902\n\n\n\n\n\n\n\n\n\n\\(p = .9\\)\nAverage Width\n.238\n.097\n.014\n\n\n\\(p = .5\\)\nAverage Width\n.639\n.162\n.023\n\n\n\nOverall, when \\(n=5000\\), no matter the probabilities that I used, the “large enough” assumptions holds. When \\(n=100\\) and the probability is \\(.5\\), then the assumptions hold but when \\(p=.9\\) the assumption that \\(n(1-p)&gt;10\\) doesn’t hold. The assumptions never hold when \\(n=5\\).\nAs \\(n\\) increases in size, the coverage rates increase towards the confidence level and the average widths of the confidence intervals decrease. As \\(n\\) gets quite large, say \\(5000\\), the coverage rate is very close to our confidence interval, in this case \\(90%\\). This is because as \\(n\\) gets large, the mean of the simulation gets closer to the true mean and so the average width of the interval gets smaller. For the three groups where the assumptions do not hold, the coverage rates are not very close to the confidence level. For the other three groups, the rates are clsoe to the 90% confidence interval.\nIt can be concluded that for small sample sizes where the assumptions don’t hold, the normal approximation of the binomial distribution does not do a good job. We are getting much smaller coverages than we expect for small sample sizes. For large values of \\(n\\) and especially for extremely large values, the normal approximation holds, shown by getting the coverage rate extremly close to the confidence level.\nMini Project 3: Confidence Intervals"
  },
  {
    "objectID": "posts/04-Bayesian/index.html",
    "href": "posts/04-Bayesian/index.html",
    "title": "04 - Bayesian Statistics",
    "section": "",
    "text": "Mini Project 4: Bayesian Statistics\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n# non-informative prior for this probability.\n## trying to get a mean of 3 and a probability\n## that lambda is less than 2 equal to 0.02\n\nps &lt;- seq(0, 1, length.out = 1000)\n\nnoninformative_alpha &lt;- 1\nnoninformative_beta &lt;- 1\n\nnoninformative_prior1 &lt;- dbeta(ps,\n                              noninformative_alpha, noninformative_beta)\n\n\n# an informative prior based on a clay-court match the two played in the previous year. In that match, Nadal won 46 out of 66 points on his own serve. The standard error of this estimate is 0.05657.\ntarget_mean &lt;- 46/66\n\nalphas &lt;- seq(0.1, 60, length.out = 500)\nbetas &lt;- (1-target_mean)*alphas/target_mean\n\nparam_df &lt;- tibble(alphas, betas)\nparam_df &lt;- param_df |&gt; mutate(vars = (alphas*betas)/((alphas+betas)^2*(alphas+betas+1)))\n\n\ntarget_var &lt;- (.05657)^2\n\nparam_df &lt;- param_df |&gt; mutate(dist_to_target = abs(vars - target_var))\nparam_df\n\n# A tibble: 500 × 4\n   alphas  betas   vars dist_to_target\n    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;          &lt;dbl&gt;\n 1  0.1   0.0435 0.185          0.182 \n 2  0.220 0.0957 0.161          0.157 \n 3  0.340 0.148  0.142          0.139 \n 4  0.460 0.200  0.127          0.124 \n 5  0.580 0.252  0.115          0.112 \n 6  0.700 0.304  0.105          0.102 \n 7  0.820 0.357  0.0970         0.0938\n 8  0.940 0.409  0.0899         0.0867\n 9  1.06  0.461  0.0838         0.0806\n10  1.18  0.513  0.0784         0.0752\n# ℹ 490 more rows\n\nparam_df |&gt; filter(dist_to_target == min(dist_to_target))\n\n# A tibble: 1 × 4\n  alphas betas    vars dist_to_target\n   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;          &lt;dbl&gt;\n1   45.4  19.7 0.00320     0.00000374\n\n\n\n# an informative prior based on a sports announcer, who claims that they think Nadal wins about 75% of the points on his serve against Djokovic. They are also “almost sure” that Nadal wins no less than 70% of his points on serve against Djokovic.\n## trying to get a mean of 3 and a probability\n## that lambda is less than 2 equal to 0.02\nalphas &lt;- seq(0.01, 100, length.out = 2000) \nks &lt;- alphas * (1 - 0.75) / 0.75 \n\ntarget_prob &lt;- .02\nprob_less_point7 &lt;- pgamma(.7, alphas, ks)\n\ntibble(alphas, ks, prob_less_point7) |&gt;\n  mutate(close_to_target = abs(prob_less_point7 - target_prob)) |&gt;\n  filter(close_to_target == min(close_to_target))\n\n# A tibble: 1 × 4\n  alphas    ks prob_less_point7 close_to_target\n   &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt;           &lt;dbl&gt;\n1   3.66  1.22           0.0199        0.000104\n\n\n\nlibrary(tidyverse)\nps &lt;- seq(0, 1, length.out = 1000)\n\nnoninformative_alpha &lt;- 1 ## CHANGE THIS TO YOUR ALPHA\nnoninformative_beta &lt;- 1  ## CHANGE THIS TO YOUR BETA\n\ninformative_alpha1 &lt;- 45.36\ninformative_beta1 &lt;- 19.72\n\nnoninformative_prior &lt;- dbeta(ps, noninformative_alpha,\n                           noninformative_beta)\ninformative_prior1 &lt;- dbeta(ps,\n                              informative_alpha1, informative_beta1)\n\n## CHANGE THESE\ninformative_alpha_prior2 &lt;- 3.66\ninformative_beta_prior2 &lt;- 1.22\ninformative_prior2 &lt;- dbeta(ps, informative_alpha_prior2,\n                          informative_beta_prior2)\n\n\nplot_df &lt;- tibble(ps, noninformative_prior, informative_prior1,\n                     informative_prior2) |&gt;\n  pivot_longer(2:4, names_to = \"distribution\", values_to = \"density\") |&gt;\n  separate(distribution, into = c(\"prior_type\", \"distribution\"))\n\nggplot(data = plot_df, aes(x = ps, y = density, colour = prior_type,\n                           linetype = distribution)) +\n  geom_line() +\n  scale_colour_viridis_d(end = 0.9) +\n  theme_minimal() +\n  labs(x = \"p\")\n\n\n\n\n\n# Non-informative posterior\nnoninformative_alpha_post &lt;- 1 + 56\nnoninformative_beta_post &lt;- 1 + 28\nmean1 &lt;- noninformative_alpha_post / (noninformative_alpha_post + noninformative_beta_post)\nci1 &lt;- qbeta(c(0.05, 0.95), noninformative_alpha_post, noninformative_beta_post)\n\ncat(\"1. Non-informative Posterior:\\n\")\n\n1. Non-informative Posterior:\n\ncat(\"   Mean:\", mean1, \"\\n\")\n\n   Mean: 0.6627907 \n\ncat(\"   90% Credible Interval:\", ci1[1], \"-\", ci1[2], \"\\n\\n\")\n\n   90% Credible Interval: 0.5772453 - 0.7440061 \n\n# Informative posterior from previous match\nalphapost1 &lt;- 45.36 + 56\nbetapost1 &lt;- 19.72 + 28\nmean2 &lt;- alphapost1 / (alphapost1 + betapost1)\nci2 &lt;- qbeta(c(0.05, 0.95), alphapost1, betapost1)\n\ncat(\"2. Informative Posterior (Match Data):\\n\")\n\n2. Informative Posterior (Match Data):\n\ncat(\"   Mean:\", mean2, \"\\n\")\n\n   Mean: 0.6799034 \n\ncat(\"   90% Credible Interval:\", ci2[1], \"-\", ci2[2], \"\\n\\n\")\n\n   90% Credible Interval: 0.61589 - 0.7411633 \n\n# Informative posterior from sports announcer\nalphapost2 &lt;- 3.66 + 56\nbetapost2 &lt;- 1.22 + 28\nmean3 &lt;- alphapost2 / (alphapost2 + betapost2)\nci3 &lt;- qbeta(c(0.05, 0.95), alphapost2, betapost2)\n\ncat(\"3. Informative Posterior (Announcer's Belief):\\n\")\n\n3. Informative Posterior (Announcer's Belief):\n\ncat(\"   Mean:\", mean3, \"\\n\")\n\n   Mean: 0.6712421 \n\ncat(\"   90% Credible Interval:\", ci3[1], \"-\", ci3[2], \"\\n\")\n\n   90% Credible Interval: 0.5875315 - 0.7505465 \n\n\n\nlibrary(tidyverse)\nps &lt;- seq(0, 1, length.out = 1000)\n\n#noninformative posterior\nnoninformative_post &lt;- dbeta(ps, noninformative_alpha_post,\n                           noninformative_beta_post)\n#informative posterior 1\ninformative_post1 &lt;- dbeta(ps,\n                              alphapost1, betapost1)\n\n#informative posterior 2\ninformative_post2 &lt;- dbeta(ps, alphapost2,\n                          betapost2)\n\n#plot\nplot_df &lt;- tibble(ps, noninformative_post, informative_post1,\n                     informative_post2) |&gt;\n  pivot_longer(2:4, names_to = \"distribution\", values_to = \"density\") |&gt;\n  separate(distribution, into = c(\"prior_type\", \"distribution\"))\n\nggplot(data = plot_df, aes(x = ps, y = density, colour = prior_type,\n                           linetype = distribution)) +\n  geom_line() +\n  scale_colour_viridis_d(end = 0.9) +\n  theme_minimal() +\n  labs(x = \"p\")\n\n\n\n\nReport:\n*In this project, we are looking how three different priors do in representing the distribution of the probability of Nadal winning a point on his serve when playing on clay courts against Djokovic. To answer this, I graphed the three priors and then updated the priors with data from the 2020 French Open. I will then explore these distributions as well as their 90% confidence intervals and means.\n*To create the noninformative prior, I just used a beta distribution with alpha and beta equal to 1. To create the prior for the observed data, I created a target mean of the probability from the data and ran through different alphas and betas to get yield a mean of .4 and a vairaince closest to the target. To create the prior for based on the sports announcer prediction we used their probability they claim in correct and run through combinations of alpha and ks to get the probability. Since they are “almost sure” that Nadal wins no less than 70% of the points I used a target_prob of .02 because it’s not likely, but not impossible. I used a gamma distribution to find this probability.For these priors, we made the assumptions that the matches were all independent, so Nadal doing well or not well before didn’t affect how he did at the 2020 French Open.\n*Graphs and intervals are above.\n*All of the posteriors are a bit different because their priors were all different and we added the same values to each of them. If I were to pick one, I would pick the post1 which is based on the prior of the other observed match. The distribution did not move too much from it’s prior and has the narrowest interval. Since the distribution didn’t move form the prior to the posterior, the variance will be lower than the other two posteriors.\n*In this mini-project, I found, with some difference depending on the prior used, the probability of Nadal winning a point when he serves againt Djokovic on clay courts is between around .58 and .74."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/02-Estimation/index.html",
    "href": "posts/02-Estimation/index.html",
    "title": "02 - Estimation",
    "section": "",
    "text": "Mini Project 2: Estimation\nSprinting is just running as fast as you can, right?\nWhen I first started that is exactly what I thought. I always played sports growing up, often times being the most athletic and fastest person. In 11th grade I started running track. I wasn't always the fastest, but I went to a small school so there wasn't too much competition.\nThen I started running in college and everything changed. In high school, the competition followed a normal distribution where there were some slow kids, most of the people were moderately fast, and then there were some really fast kids. And now in DIII college, occasionally there are slow people, but rarely. Then most of the people are fairly fast, then it tails out to the really fast people that could have ran DI. This closely follows a chi square distribution where most of the people are towards the left and there is a long tail to the right.\nRight now, we are in the final week of our indoor season, with just one meet left before the league championships. My personal goal is to qualify for leagues in the 60-meter dash. My personal best in the event is 7.41 and the qualifying time is 7.35. This sounds like nothing at all, but over 60 meters, it is a decent margin.\nSo will I run .06 faster than I ever have to qualify?\nEvery runner has a true parameter for how fast they could run in an event. This is an unknown time that you've never run before. In every race a person runs, they get an estimate of this parameter. This is a single outcome that has many aspects to it. One way to look at it, is that you, the runner, are the estimator that is generating these estimates. In a race, there are so many variables: fitness, nutrition, hydration, mindset, and then your overall execution of the race. This also means that in every race you obtain a random variable that might help you predict your true parameter. Your season could be looked at as a random sample of all your times throughout the season that would help with a estimation. There are so many times that you could run based on the given day you are running and your execution of the race. This can create a decent amount of variance in the races, but the more you run, say in a season, the variance will decrease, given you stay healthy.In theory, the more races you run, the faster you get and you will run your true time, which might be true until you reach a certain age or get injuries. This follows closely to consistency, where as the number of races you run approaches infinity (although not physically possible), the probability that our estimator produces a value close to our true parameter is 1.  As the season progresses you should be approaching your true potential. But seasons don't always go smoothly, you can often have an off day where you're not feeling one hundred percent or you don't execute your race like you wanted to. For me, I've had races where I've had horrible block starts that throw off the whole race and I've also had races where I've gotten out of the blocks really well but then I tense up when I'm upright. This type of thing can introduce bias where what you expect to happen is completely off what you know you can run. On the contrary, when you work on something specific, like practicing block starts or focusing on upright running form, you are increasing your likelihood of running well.\nBased on all of my times throughout the season, you might estimate that I'm not going to run 7.35 on Friday because of the fact I've been in the 7.4's all season. But I am hoping I create an enormous amount of bias and run faster than what my expected time is based on this season."
  },
  {
    "objectID": "posts/01-Simulation/index.html",
    "href": "posts/01-Simulation/index.html",
    "title": "01 - Simulation",
    "section": "",
    "text": "Mini Project 1: Simulation\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nNormal Min\n\nn &lt;- 5       # sample size\nmu &lt;- 10     # population mean\nsigma &lt;- 2   # population standard deviation\n\n# generate a random sample of n observations from a normal population\nnorm_single_sample &lt;- rnorm(n, mu, sigma) |&gt; round(2)\n# look at the sample\nnorm_single_sample \n\n[1] 13.26  6.17  8.40 11.73  8.92\n\n# compute the sample min\nnorm_sample_min &lt;- min(norm_single_sample)\n# look at the sample min\nnorm_sample_min   \n\n[1] 6.17\n\n# generate a range of values that span the population\nplot_df &lt;- tibble(xvals = seq(mu - 4 * sigma, mu + 4 * sigma, length.out = 500)) |&gt;\n  mutate(xvals_density = dnorm(xvals, mu, sigma))\n\n## plot the population model density curve\nggplot(data = plot_df, aes(x = xvals, y = xvals_density)) +\n  geom_line() +\n  theme_minimal() +\n  ## add the sample points from your sample\n  geom_jitter(data = tibble(norm_single_sample), aes(x = norm_single_sample, y = 0),\n              width = 0, height = 0.005) +\n  ## add a line for the sample min\n  geom_vline(xintercept = norm_sample_min, colour = \"red\") +\n  labs(x = \"y\", y = \"density\",\n       title = \"Normal with Mu = 10 and sigma = 2\")\n\n\n\n\n\nn &lt;- 5            # sample size\nmu &lt;- 10          # population mean\nsigma &lt;- 2        # population standard deviation\n\ngenerate_samp_min &lt;- function(mu, sigma, n) {\n  \n  norm_single_sample &lt;- rnorm(n, mu, sigma)\n  norm_sample_min &lt;- min(norm_single_sample)\n  \n  return(norm_sample_min)\n}\n\n## test function once:\ngenerate_samp_min(mu = mu, sigma = sigma, n = n)\n\n[1] 8.838446\n\nnsim &lt;- 5000      # number of simulations\n\n## code to map through the function. \n## the \\(i) syntax says to just repeat the generate_samp_min function\n## nsim times\nnorm_mins &lt;- map_dbl(1:nsim, \\(i) generate_samp_min(mu = mu, sigma = sigma, n = n))\n\n## print some of the 5000 mins\n## each number represents the sample min from __one__ sample.\nnorm_mins_df &lt;- tibble(norm_mins)\nnorm_mins_df\n\n# A tibble: 5,000 × 1\n   norm_mins\n       &lt;dbl&gt;\n 1      7.23\n 2      7.59\n 3      7.57\n 4      8.03\n 5      9.16\n 6      9.07\n 7      7.57\n 8      8.12\n 9      8.63\n10      6.72\n# ℹ 4,990 more rows\n\nggplot(data = norm_mins_df, aes(x = norm_mins)) +\n  geom_histogram(colour = \"deeppink4\", fill = \"deeppink1\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample mins\",\n       title = paste(\"Sampling Distribution of the \\nSample min when n =\", n))\n\n\n\nnorm_mins_df |&gt;\n  summarise(mean_samp_dist = mean(norm_mins),\n            var_samp_dist = var(norm_mins),\n            sd_samp_dist = sd(norm_mins))\n\n# A tibble: 1 × 3\n  mean_samp_dist var_samp_dist sd_samp_dist\n           &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1           7.67          1.82         1.35\n\n\nNormal Max\n\nn &lt;- 5       # sample size\nmu &lt;- 10     # population mean\nsigma &lt;- 2   # population standard deviation\n\n# generate a random sample of n observations from a normal population\nsingle_sample &lt;- rnorm(n, mu, sigma) |&gt; round(2)\n# look at the sample\nsingle_sample \n\n[1] 10.82  8.46 12.88 12.97  4.85\n\n# compute the sample min\nsample_max &lt;- max(single_sample)\n# look at the sample min\nsample_max   \n\n[1] 12.97\n\n# generate a range of values that span the population\nplot_df &lt;- tibble(xvals = seq(mu - 4 * sigma, mu + 4 * sigma, length.out = 500)) |&gt;\n  mutate(xvals_density = dnorm(xvals, mu, sigma))\n\n## plot the population model density curve\nggplot(data = plot_df, aes(x = xvals, y = xvals_density)) +\n  geom_line() +\n  theme_minimal() +\n  ## add the sample points from your sample\n  geom_jitter(data = tibble(single_sample), aes(x = single_sample, y = 0),\n              width = 0, height = 0.005) +\n  ## add a line for the sample min\n  geom_vline(xintercept = sample_max, colour = \"red\") +\n  labs(x = \"y\", y = \"density\",\n       title = \"Normal with Mu = 10 and sigma = 2\")\n\n\n\n\n\nn &lt;- 5           # sample size\nmu &lt;- 10          # population mean\nsigma &lt;- 2        # population standard deviation\n\ngenerate_samp_max &lt;- function(mu, sigma, n) {\n  \n  single_sample &lt;- rnorm(n, mu, sigma)\n  sample_max &lt;- max(single_sample)\n  \n  return(sample_max)\n}\n\n## test function once:\ngenerate_samp_max(mu = mu, sigma = sigma, n = n)\n\n[1] 12.11905\n\nnsim &lt;- 5000      # number of simulations\n\n## code to map through the function. \n## the \\(i) syntax says to just repeat the generate_samp_min function\n## nsim times\nmaxs &lt;- map_dbl(1:nsim, \\(i) generate_samp_max(mu = mu, sigma = sigma, n = n))\n\n## print some of the 5000 mins\n## each number represents the sample min from __one__ sample.\nnorm_maxs_df &lt;- tibble(maxs)\nnorm_maxs_df\n\n# A tibble: 5,000 × 1\n    maxs\n   &lt;dbl&gt;\n 1  11.3\n 2  13.8\n 3  12.6\n 4  11.7\n 5  10.5\n 6  10.4\n 7  12.6\n 8  11.5\n 9  14.6\n10  13.6\n# ℹ 4,990 more rows\n\nggplot(data = norm_maxs_df, aes(x = maxs)) +\n  geom_histogram(colour = \"deeppink4\", fill = \"deeppink1\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample maxs\",\n       title = paste(\"Sampling Distribution of the \\nSample max when n =\", n))\n\n\n\nnorm_maxs_df |&gt;\n  summarise(mean_samp_dist = mean(maxs),\n            var_samp_dist = var(maxs),\n            sd_samp_dist = sd(maxs))\n\n# A tibble: 1 × 3\n  mean_samp_dist var_samp_dist sd_samp_dist\n           &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1           12.3          1.77         1.33\n\n\nUniform Min\n\nn &lt;- 5       # sample size\ntheta1 &lt;- 7\ntheta2 &lt;- 13\nmu &lt;- (theta1+theta2)/2   # population mean\nsigma &lt;- sqrt(((theta1+theta2)^2)/12 ) # population standard deviation\n\ngenerate_unif_min &lt;- function(theta1,theta2, n) {\n  \n  unif_single_sample &lt;- runif(n, theta1,theta2)\n  unif_sample_min &lt;- min(unif_single_sample)\n  \n  return(unif_sample_min)\n}\n\n## test function once:\ngenerate_unif_min(theta1 = theta1, theta2=theta2, n = n)\n\n[1] 7.121323\n\n#&gt; [1] 3.915946\n\nnsim &lt;- 5000      # number of simulations\n\nunif_mins &lt;- map_dbl(1:nsim, \\(i) generate_unif_min(theta1 = theta1, theta2=theta2, n = n))\n\n## print some of the 5000 means\n## each number represents the sample mean from __one__ sample.\nunif_mins_df &lt;- tibble(unif_mins)\nunif_mins_df\n\n# A tibble: 5,000 × 1\n   unif_mins\n       &lt;dbl&gt;\n 1      7.02\n 2      8.54\n 3      7.05\n 4      8.05\n 5      7.88\n 6      8.29\n 7     10.2 \n 8      7.83\n 9      7.27\n10      7.47\n# ℹ 4,990 more rows\n\nggplot(data = unif_mins_df, aes(x = unif_mins)) +\n  geom_histogram(colour = \"darkolivegreen4\", fill = \"darkolivegreen1\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample Mins\",\n       title = paste(\"Sampling Distribution of the \\nSample min when n =\", n))\n\n\n\n\n\nunif_mins_df |&gt;\n  summarise(mean_samp_dist = mean(unif_mins),\n            var_samp_dist = var(unif_mins),\n            sd_samp_dist = sd(unif_mins))\n\n# A tibble: 1 × 3\n  mean_samp_dist var_samp_dist sd_samp_dist\n           &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1           7.99         0.695        0.834\n\n\nUniform Max\n\nn &lt;- 5       # sample size\ntheta1 &lt;- 7\ntheta2 &lt;- 13\nmu &lt;- (theta1+theta2)/2   # population mean\nsigma &lt;- sqrt(((theta1+theta2)^2)/12 ) # population standard deviation\n\ngenerate_unif_max &lt;- function(theta1,theta2, n) {\n  \n  unif_single_sample &lt;- runif(n, theta1,theta2)\n  unif_sample_max &lt;- max(unif_single_sample)\n  \n  return(unif_sample_max)\n}\n\n## test function once:\ngenerate_unif_max(theta1 = theta1, theta2=theta2, n = n)\n\n[1] 12.16577\n\n#&gt; [1] 3.915946\n\nnsim &lt;- 5000      # number of simulations\n\nunif_maxs &lt;- map_dbl(1:nsim, \\(i) generate_unif_max(theta1 = theta1, theta2=theta2, n = n))\n\n## print some of the 5000 means\n## each number represents the sample mean from __one__ sample.\nunif_maxs_df &lt;- tibble(unif_maxs)\nunif_maxs_df\n\n# A tibble: 5,000 × 1\n   unif_maxs\n       &lt;dbl&gt;\n 1      11.8\n 2      12.3\n 3      11.1\n 4      11.6\n 5      12.4\n 6      10.8\n 7      12.8\n 8      12.5\n 9      10.6\n10      12.0\n# ℹ 4,990 more rows\n\nggplot(data = unif_maxs_df, aes(x = unif_maxs)) +\n  geom_histogram(colour = \"darkolivegreen4\", fill = \"darkolivegreen1\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample Maxs\",\n       title = paste(\"Sampling Distribution of the \\nSample max when n =\", n))\n\n\n\nunif_maxs_df |&gt;\n  summarise(mean_samp_dist = mean(unif_maxs),\n            var_samp_dist = var(unif_maxs),\n            sd_samp_dist = sd(unif_maxs))\n\n# A tibble: 1 × 3\n  mean_samp_dist var_samp_dist sd_samp_dist\n           &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1           12.0         0.738        0.859\n\n\nExponential Min\n\nn &lt;- 5       # sample size\nlambda &lt;- .5\nmu &lt;- 1 / lambda   # population mean\nsigma &lt;- sqrt(1 / lambda ^ 2)  # population standard deviation\n\ngenerate_exp_min &lt;- function(lambda, n) {\n  \n  exp_single_sample &lt;- rexp(n, lambda)\n  exp_sample_min &lt;- min(exp_single_sample)\n  \n  return(exp_sample_min)\n}\n\n## test function once:\ngenerate_exp_min(lambda = lambda, n = n)\n\n[1] 0.002978954\n\n#&gt; [1] 3.915946\n\nnsim &lt;- 5000      # number of simulations\n\nexp_mins &lt;- map_dbl(1:nsim, \\(i) generate_exp_min(lambda = lambda, n = n))\n\n## print some of the 5000 means\n## each number represents the sample mean from __one__ sample.\nexp_mins_df &lt;- tibble(exp_mins)\nexp_mins_df\n\n# A tibble: 5,000 × 1\n   exp_mins\n      &lt;dbl&gt;\n 1   0.233 \n 2   0.778 \n 3   0.888 \n 4   0.116 \n 5   0.407 \n 6   0.330 \n 7   0.0195\n 8   1.43  \n 9   0.687 \n10   2.68  \n# ℹ 4,990 more rows\n\nggplot(data = exp_mins_df, aes(x = exp_mins)) +\n  geom_histogram(colour = \"darkolivegreen4\", fill = \"darkolivegreen1\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample Mins\",\n       title = paste(\"Sampling Distribution of the \\nSample min when n =\", n))\n\n\n\n\n\nexp_mins_df |&gt;\n  summarise(mean_samp_dist = mean(exp_mins),\n            var_samp_dist = var(exp_mins),\n            sd_samp_dist = sd(exp_mins))\n\n# A tibble: 1 × 3\n  mean_samp_dist var_samp_dist sd_samp_dist\n           &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1          0.403         0.165        0.406\n\n\nExponential Max\n\nn &lt;- 5    # sample size\nlambda &lt;- .5\nmu &lt;- 1 / lambda   # population mean\nsigma &lt;- sqrt(1 / lambda ^ 2)  # population standard deviation\n\ngenerate_exp_max &lt;- function(lambda, n) {\n  \n  exp_single_sample &lt;- rexp(n, lambda)\n  exp_sample_max &lt;- max(exp_single_sample)\n  \n  return(exp_sample_max)\n}\n\n## test function once:\ngenerate_exp_max(lambda = lambda, n = n)\n\n[1] 4.968905\n\n#&gt; [1] 3.915946\n\nnsim &lt;- 5000      # number of simulations\n\nexp_maxs &lt;- map_dbl(1:nsim, \\(i) generate_exp_max(lambda = lambda, n = n))\n\n## print some of the 5000 means\n## each number represents the sample mean from __one__ sample.\nexp_maxs_df &lt;- tibble(exp_maxs)\nexp_maxs_df\n\n# A tibble: 5,000 × 1\n   exp_maxs\n      &lt;dbl&gt;\n 1     4.47\n 2     4.26\n 3     4.65\n 4     3.63\n 5     4.15\n 6     5.78\n 7     5.80\n 8     5.44\n 9     3.71\n10     3.80\n# ℹ 4,990 more rows\n\nggplot(data = exp_maxs_df, aes(x = exp_maxs)) +\n  geom_histogram(colour = \"darkolivegreen4\", fill = \"darkolivegreen1\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample Mins\",\n       title = paste(\"Sampling Distribution of the \\nSample max when n =\", n))\n\n\n\n\n\nexp_maxs_df |&gt;\n  summarise(mean_samp_dist = mean(exp_maxs),\n            var_samp_dist = var(exp_maxs),\n            sd_samp_dist = sd(exp_maxs))\n\n# A tibble: 1 × 3\n  mean_samp_dist var_samp_dist sd_samp_dist\n           &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1           4.54          5.67         2.38\n\n\nBeta Min\n\nn &lt;- 5       # sample size\nalpha &lt;- 8\nbeta &lt;- 2\nmu &lt;- (alpha)/(alpha+beta)  # population mean\nsigma &lt;- sqrt((alpha*beta)/(((alpha+beta)^2)*(alpha+beta+1)) ) # population standard deviation\n\ngenerate_beta_min &lt;- function(alpha,beta, n) {\n  \n  beta_single_sample &lt;- rbeta(n, alpha,beta)\n  beta_sample_min &lt;- min(beta_single_sample)\n  \n  return(beta_sample_min)\n}\n\n## test function once:\ngenerate_beta_min(alpha = alpha, beta=beta, n = n)\n\n[1] 0.6964316\n\n#&gt; [1] 3.915946\n\nnsim &lt;- 5000      # number of simulations\n\nbeta_mins &lt;- map_dbl(1:nsim, \\(i) generate_beta_min(alpha = alpha, beta=beta, n = n))\n\n## print some of the 5000 means\n## each number represents the sample mean from __one__ sample.\nbeta_mins_df &lt;- tibble(beta_mins)\nbeta_mins_df\n\n# A tibble: 5,000 × 1\n   beta_mins\n       &lt;dbl&gt;\n 1     0.716\n 2     0.713\n 3     0.565\n 4     0.404\n 5     0.518\n 6     0.776\n 7     0.810\n 8     0.341\n 9     0.539\n10     0.628\n# ℹ 4,990 more rows\n\nggplot(data = beta_mins_df, aes(x = beta_mins)) +\n  geom_histogram(colour = \"darkolivegreen4\", fill = \"darkolivegreen1\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample Mins\",\n       title = paste(\"Sampling Distribution of the \\nSample min when n =\", n))\n\n\n\n\n\nbeta_mins_df |&gt;\n  summarise(mean_samp_dist = mean(beta_mins),\n            var_samp_dist = var(beta_mins),\n            sd_samp_dist = sd(beta_mins))\n\n# A tibble: 1 × 3\n  mean_samp_dist var_samp_dist sd_samp_dist\n           &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1          0.648        0.0113        0.106\n\n\nBeta Max\n\nn &lt;- 5       # sample size\nalpha &lt;- 8\nbeta &lt;- 2\nmu &lt;- (alpha)/(alpha+beta)  # population mean\nsigma &lt;- sqrt((alpha*beta)/(((alpha+beta)^2)*(alpha+beta+1)) ) # population standard deviation\n\ngenerate_beta_max &lt;- function(alpha,beta, n) {\n  \n  single_sample &lt;- rbeta(n, alpha,beta)\n  sample_max &lt;- max(single_sample)\n  \n  return(sample_max)\n}\n\n## test function once:\ngenerate_beta_max(alpha = alpha, beta=beta, n = n)\n\n[1] 0.7841302\n\n#&gt; [1] 3.915946\n\nnsim &lt;- 5000      # number of simulations\n\nmaxs &lt;- map_dbl(1:nsim, \\(i) generate_beta_max(alpha = alpha, beta=beta, n = n))\n\n## print some of the 5000 means\n## each number represents the sample mean from __one__ sample.\nbeta_maxs_df &lt;- tibble(maxs)\nbeta_maxs_df\n\n# A tibble: 5,000 × 1\n    maxs\n   &lt;dbl&gt;\n 1 0.808\n 2 0.941\n 3 0.975\n 4 0.875\n 5 0.914\n 6 0.968\n 7 0.879\n 8 0.962\n 9 0.779\n10 0.898\n# ℹ 4,990 more rows\n\nggplot(data = beta_maxs_df, aes(x = maxs)) +\n  geom_histogram(colour = \"darkolivegreen4\", fill = \"darkolivegreen1\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample Maxs\",\n       title = paste(\"Sampling Distribution of the \\nSample max when n =\", n))\n\n\n\nbeta_maxs_df |&gt;\n  summarise(mean_samp_dist = mean(maxs),\n            var_samp_dist = var(maxs),\n            sd_samp_dist = sd(maxs))\n\n# A tibble: 1 × 3\n  mean_samp_dist var_samp_dist sd_samp_dist\n           &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1          0.922       0.00216       0.0465\n\n\n\nlibrary(tidyverse)\n## create population graphs\n\n\nnorm_df &lt;- tibble(x = seq(3, 17, length.out = 1000),\n                  dens = dnorm(x, mean = 10, sd = 2),\n                  pop = \"normal(10, 4)\")\nunif_df &lt;- tibble(x = seq(7, 13, length.out = 1000),\n                  dens = dunif(x, 7, 13),\n                  pop = \"uniform(7, 13)\")\nexp_df &lt;- tibble(x = seq(0, 10, length.out = 1000),\n                 dens = dexp(x, 0.5),\n                 pop = \"exp(0.5)\")\nbeta_df &lt;- tibble(x = seq(0, 1, length.out = 1000),\n                  dens = dbeta(x, 8, 2),\n                  pop = \"beta(8, 2)\")\n\npop_plot &lt;- bind_rows(norm_df, unif_df, exp_df, beta_df) |&gt;\n  mutate(pop = fct_relevel(pop, c(\"normal(10, 4)\", \"uniform(7, 13)\",\n                                  \"exp(0.5)\", \"beta(8, 2)\")))\n\n\nggplot(data = pop_plot, aes(x = x, y = dens)) +\n  geom_line() +\n  theme_minimal() +\n  facet_wrap(~ pop, nrow = 1, scales = \"free\") +\n  labs(title = \"Population Distributions for Each Simulation Setting\")\n\n\n\n\nI wasn’t able to plot the histograms together like this, so I made histograms throughout the document for Ymax and Ymin of each distribution.\n\nTable of Results\n\n\n\n\n\n\n\n\n\n\n\\(\\text{N}(\\mu = 10, \\sigma^2 = 4)\\)\n\\(\\text{Unif}(\\theta_1 = 7, \\theta_2 = 13)\\)\n\\(\\text{Exp}(\\lambda = 0.5)\\)\n\\(\\text{Beta}(\\alpha = 8, \\beta = 2)\\)\n\n\n\n\n\\(\\text{E}(Y_{min})\\)\n7.65\n7.98\n.4\n.65\n\n\n\\(\\text{E}(Y_{max})\\)\n12.34\n12.01\n4.55\n.93\n\n\n\n\n\n\n\n\n\n\\(\\text{SE}(Y_{min})\\)\n1.35\n.83\n.4\n.11\n\n\n\\(\\text{SE}(Y_{max})\\)\n1.35\n.83\n2.37\n.045\n\n\n\n\nn &lt;- 5\n## CHANGE 0 and 3 to represent where you want your graph to start and end\n## on the x-axis\nx &lt;- seq(0, 18, length.out = 1000)\n## CHANGE to be the pdf you calculated. Note that, as of now, \n## this is not a proper density (it does not integrate to 1).\ndensity &lt;- 5 * (1-exp(-(.5)*x)) ^(4) * (.5*exp(-(.5)*x))\n\n\n## put into tibble and plot\nsamp_max_df &lt;- tibble(x, density)\nggplot(data = samp_max_df, aes(x = x, y = density)) +\n  geom_line() +\n  theme_minimal()+\n  labs(title= \"PDF for Ymax of Exp(.5)\")\n\n\n\n\n\nn &lt;- 5\n## CHANGE 0 and 3 to represent where you want your graph to start and end\n## on the x-axis\nx &lt;- seq(0, 5, length.out = 1000)\n## CHANGE to be the pdf you calculated. Note that, as of now, \n## this is not a proper density (it does not integrate to 1).\ndensity &lt;- 2.5*exp(-(2.5)*x)\n\n\n## put into tibble and plot\nsamp_min_df &lt;- tibble(x, density)\nggplot(data = samp_min_df, aes(x = x, y = density)) +\n  geom_line() +\n  theme_minimal() +\n  labs(title= \"PDF for Ymin of Exp(.5)\")"
  },
  {
    "objectID": "posts/05-HypothesisTesting/index.html",
    "href": "posts/05-HypothesisTesting/index.html",
    "title": "05 - Hypothesis Testing",
    "section": "",
    "text": "Mini Project 5: Hypothesis Testing\n\nTowards the end of Section 1, the authors say \"As 'statistical significance' is used less, statistical thinking will be used more.\" Elaborate on what you think the authors mean. Give some examples of what you think embodies \"statistical thinking.\"\n\nI think when the author said this, they think research should look beyond statistical significance which allows for more variety of results that can be interpreted a variety of ways. I think this is especially important today in a world where lots of things are becoming automated or AI generated. It takes a person, though, to be able to come up with a model or idea that might not fit the standard or that turns out not to be 'statistically significant' but may still make sense. When I took econometrics, and this is true for most economic research, the p value was barely looked at. It was more about thinking if the variable made sense, thinking about if there might be correlation between variables or endogeneity. An example from econometrics would be that often times you're asked to create a model using different variables. You could try to throw every variable into the model and everything is significant. But often variables are highly correlated or provide the same information. So even though they pass this significance test, you can simplify the model to get a more accurate prediction. This couldn't be done without statistical thinking. Also, the author isn't saying don't completely ignore the p value. It varies person to person and situation to situation for the level they care about. So, leaving it up to the user or reader to determine if they think it is reasonable to use is important. Being able to think this way without solely relying on statistical significance will be essential if doing research especially with emerging technology which doesn't necessarily have this ability to think significantly.\n\nSection 2, third paragraph: The authors state \"A label of statistical significance adds nothing to what is already conveyed by the value of p; in fact, this dichotomization of p-values makes matters worse.\" Elaborate on what you think the authors mean.\n\nThe author is saying that the p value speaks for itself and that a label is not necessarily.  Not having a label allows the researcher to make their own decision about whether they want to include the variable or whatever it might be. If the followed what was the standard, saying it’s not significant above a certain p value limits the possibilities for research. Getting rid of the label of statistical significance allows for both the researcher and the consumer of the output to make their own decision about whether they think it makes sense or not.  \n\nSection 2, end of first column: The authors state \"For the integrity of scientific publishing and research dissemination, therefore, whether a p-value passes any arbitrary threshold should not be considered at all when deciding which results to present or highlight.\" Do you agree or disagree? How should it be decided which results to present/highlight in scientific publishing?\n\nI think at least mentioning the p value makes sense in scientific publishing although it should not be the main focus by any means. The authors say that only including finding that have a certain p value creates bias, but I believe not including or looking at p values would create even more bias. It would make it very easy to skew results or create results that aren't accurate at all. That is why I think finding that don't pass a p value should be included if the researcher wants but the p values should be as well for the readers use. For an average reader or someone skimming over the research, it would be very easy to create inaccurate results to sway people. I also think including the p value allows the reader to agree or disagree with the model. Like what we did in class, for certain p values we can have 'moderate evidence', 'strong evidence', or 'no evidence'.  Having p values included and giving this insight to the reader is important for the reader to make a decision about whether they like this model or not. \n\nSection 3, end of page 2: The authors state \"The statistical community has not yet converged on a simple paradigm for the use of statistical inference in scientific research – and in fact it may never do so. A one-size-fits-all approach to statistical inference is an inappropriate expectation.\" Do you agree or disagree? Explain.\n\nI do agree that a one-size-fits-all approach is not a good standard to have for statistical inference. I think that since this technique is used in so many different sectors with such varying importance, one single approach to replace statistical significance is not appropriate, much like only looking at p values isn't appropriate in most cases. I think it could be possible to make categories that research and findings fall into and have a standard paradigm for each category, but I'm not entirely sure what that would look like.\n\nSection 3.2: The authors note that they are envisioning \"a sort of 'statistical thoughtfulness'.\" What do you think \"statistical thoughtfulness\" means? What are some ways to demonstrate \"statistical thoughtfulness\" in an analysis?\n\nStatistical analysis means that you have a reason for everything you are doing. I think first off; to be able to have statistical thoughtfulness, you need to have a strong foundational understanding of statistics and the data you are working with.  In econometrics, the very first thing we did before running any regressions or anything else, we needed to understand the data fully. In an analysis, to demonstrate statistical thoughtfulness, you need to do everything with a purpose. For example, you're not adding variables into a model to just to add variables. You're doing your research with the goal of including everything you think needs to be incorporated while aiming for parsimony.  I think also writing your exploratory process alonside finished results is a way to demonstrate to the consumer of the findings that you did your analysis with statistical thoughtfulness. Finally, having a section in your findings of any assumptions you made or places where you could have done something differently or better goes along with the statistical thoughtfulness.  \n\nSection 3.2.4: A few of the authors of papers in this special issue argue that some of the terminology used in statistics, such as \"significance\" and \"confidence\" can be misleading, and they propose the use of \"compatibility\" instead. What do you think they believe the problem is? Do you agree or disagree (that there is a problem and that changing the name will help)?\n\nI think the authors think the problem is that the words significance and confidence are too charged with it being either right(significant) or wrong(insignificant). Changing it to compatible is more neutral, not necessarily a right or wrong but more of a 'it could work' but it should really be thought about using your statistical thoughtfulness. I do think changing the name could help, but only to some degree. Hearing a '95% confidence interval' surely makes people feel very, if not overly, confident about the correctness of the test, whatever the test may be.  As someone who is hearing compatibility rather than significance or confidence, it does seem less loaded, meaning I don't feel as strong in favor. But I also think if statisticians and researchers were to be a change from significance/confidence to compatibility, I think they would be used interchangeably and the distinction between them wouldn't be much over time.\n\nFind a quote or point that really strikes you (i.e., made you think). What is the quote (and tell me where to find it), and why does it stand out to you?\n\nThird paragraph of section 5.\nGoodman observes that statisticians alone cannot address the problem, and that \"any approach involving only statisticians will not succeed.\" He calls on statisticians to ally themselves \"both with scientists in other fields and with broader based, multidisciplinary scientific reform movements. What statisticians\ncan do within our own discipline is important, but to effectively disseminate or implement virtually any method or policy, we need partners.\"\nThis section stuck me because I was thinking about this from the moment I started reading. I was wondering to myself how this change would come about. In econometrics we barely looked at p values, but in STAT 213 we rely very heavily on p values. It got me thinking whether some institutions and even if departments at St.  Lawrence have talked about abandoning p values or not teaching them as heavily. This article was published six years ago, so I wonder if this change is still trying to take place or how much traction it’s gotten since 2019."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "blog_326",
    "section": "",
    "text": "03 - Confidence Intervals\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n04 - Bayesian Statistics\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n02 - Estimation\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n01 - Simulation\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n05 - Hypothesis Testing\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nApr 28, 2025\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nApr 25, 2025\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]