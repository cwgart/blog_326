{
  "hash": "c3192cdd6314f9b8e64509c8de9e1aac",
  "result": {
    "markdown": "---\ntitle: \"04 - Bayesian Statistics\"\n---\n\n\nMini Project 4: Bayesian Statistics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# non-informative prior for this probability.\n## trying to get a mean of 3 and a probability\n## that lambda is less than 2 equal to 0.02\n\nps <- seq(0, 1, length.out = 1000)\n\nnoninformative_alpha <- 1\nnoninformative_beta <- 1\n\nnoninformative_prior1 <- dbeta(ps,\n                              noninformative_alpha, noninformative_beta)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# an informative prior based on a clay-court match the two played in the previous year. In that match, Nadal won 46 out of 66 points on his own serve. The standard error of this estimate is 0.05657.\ntarget_mean <- 46/66\n\nalphas <- seq(0.1, 60, length.out = 500)\nbetas <- (1-target_mean)*alphas/target_mean\n\nparam_df <- tibble(alphas, betas)\nparam_df <- param_df |> mutate(vars = (alphas*betas)/((alphas+betas)^2*(alphas+betas+1)))\n\n\ntarget_var <- (.05657)^2\n\nparam_df <- param_df |> mutate(dist_to_target = abs(vars - target_var))\nparam_df\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 500 × 4\n   alphas  betas   vars dist_to_target\n    <dbl>  <dbl>  <dbl>          <dbl>\n 1  0.1   0.0435 0.185          0.182 \n 2  0.220 0.0957 0.161          0.157 \n 3  0.340 0.148  0.142          0.139 \n 4  0.460 0.200  0.127          0.124 \n 5  0.580 0.252  0.115          0.112 \n 6  0.700 0.304  0.105          0.102 \n 7  0.820 0.357  0.0970         0.0938\n 8  0.940 0.409  0.0899         0.0867\n 9  1.06  0.461  0.0838         0.0806\n10  1.18  0.513  0.0784         0.0752\n# ℹ 490 more rows\n```\n:::\n\n```{.r .cell-code}\nparam_df |> filter(dist_to_target == min(dist_to_target))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 4\n  alphas betas    vars dist_to_target\n   <dbl> <dbl>   <dbl>          <dbl>\n1   45.4  19.7 0.00320     0.00000374\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# an informative prior based on a sports announcer, who claims that they think Nadal wins about 75% of the points on his serve against Djokovic. They are also “almost sure” that Nadal wins no less than 70% of his points on serve against Djokovic.\n## trying to get a mean of 3 and a probability\n## that lambda is less than 2 equal to 0.02\nalphas <- seq(0.01, 100, length.out = 2000) \nks <- alphas * (1 - 0.75) / 0.75 \n\ntarget_prob <- .02\nprob_less_point7 <- pgamma(.7, alphas, ks)\n\ntibble(alphas, ks, prob_less_point7) |>\n  mutate(close_to_target = abs(prob_less_point7 - target_prob)) |>\n  filter(close_to_target == min(close_to_target))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 4\n  alphas    ks prob_less_point7 close_to_target\n   <dbl> <dbl>            <dbl>           <dbl>\n1   3.66  1.22           0.0199        0.000104\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nps <- seq(0, 1, length.out = 1000)\n\nnoninformative_alpha <- 1 ## CHANGE THIS TO YOUR ALPHA\nnoninformative_beta <- 1  ## CHANGE THIS TO YOUR BETA\n\ninformative_alpha1 <- 45.36\ninformative_beta1 <- 19.72\n\nnoninformative_prior <- dbeta(ps, noninformative_alpha,\n                           noninformative_beta)\ninformative_prior1 <- dbeta(ps,\n                              informative_alpha1, informative_beta1)\n\n## CHANGE THESE\ninformative_alpha_prior2 <- 3.66\ninformative_beta_prior2 <- 1.22\ninformative_prior2 <- dbeta(ps, informative_alpha_prior2,\n                          informative_beta_prior2)\n\n\nplot_df <- tibble(ps, noninformative_prior, informative_prior1,\n                     informative_prior2) |>\n  pivot_longer(2:4, names_to = \"distribution\", values_to = \"density\") |>\n  separate(distribution, into = c(\"prior_type\", \"distribution\"))\n\nggplot(data = plot_df, aes(x = ps, y = density, colour = prior_type,\n                           linetype = distribution)) +\n  geom_line() +\n  scale_colour_viridis_d(end = 0.9) +\n  theme_minimal() +\n  labs(x = \"p\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Non-informative posterior\nnoninformative_alpha_post <- 1 + 56\nnoninformative_beta_post <- 1 + 28\nmean1 <- noninformative_alpha_post / (noninformative_alpha_post + noninformative_beta_post)\nci1 <- qbeta(c(0.05, 0.95), noninformative_alpha_post, noninformative_beta_post)\n\ncat(\"1. Non-informative Posterior:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1. Non-informative Posterior:\n```\n:::\n\n```{.r .cell-code}\ncat(\"   Mean:\", mean1, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Mean: 0.6627907 \n```\n:::\n\n```{.r .cell-code}\ncat(\"   90% Credible Interval:\", ci1[1], \"-\", ci1[2], \"\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   90% Credible Interval: 0.5772453 - 0.7440061 \n```\n:::\n\n```{.r .cell-code}\n# Informative posterior from previous match\nalphapost1 <- 45.36 + 56\nbetapost1 <- 19.72 + 28\nmean2 <- alphapost1 / (alphapost1 + betapost1)\nci2 <- qbeta(c(0.05, 0.95), alphapost1, betapost1)\n\ncat(\"2. Informative Posterior (Match Data):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n2. Informative Posterior (Match Data):\n```\n:::\n\n```{.r .cell-code}\ncat(\"   Mean:\", mean2, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Mean: 0.6799034 \n```\n:::\n\n```{.r .cell-code}\ncat(\"   90% Credible Interval:\", ci2[1], \"-\", ci2[2], \"\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   90% Credible Interval: 0.61589 - 0.7411633 \n```\n:::\n\n```{.r .cell-code}\n# Informative posterior from sports announcer\nalphapost2 <- 3.66 + 56\nbetapost2 <- 1.22 + 28\nmean3 <- alphapost2 / (alphapost2 + betapost2)\nci3 <- qbeta(c(0.05, 0.95), alphapost2, betapost2)\n\ncat(\"3. Informative Posterior (Announcer's Belief):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n3. Informative Posterior (Announcer's Belief):\n```\n:::\n\n```{.r .cell-code}\ncat(\"   Mean:\", mean3, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Mean: 0.6712421 \n```\n:::\n\n```{.r .cell-code}\ncat(\"   90% Credible Interval:\", ci3[1], \"-\", ci3[2], \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   90% Credible Interval: 0.5875315 - 0.7505465 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nps <- seq(0, 1, length.out = 1000)\n\n#noninformative posterior\nnoninformative_post <- dbeta(ps, noninformative_alpha_post,\n                           noninformative_beta_post)\n#informative posterior 1\ninformative_post1 <- dbeta(ps,\n                              alphapost1, betapost1)\n\n#informative posterior 2\ninformative_post2 <- dbeta(ps, alphapost2,\n                          betapost2)\n\n#plot\nplot_df <- tibble(ps, noninformative_post, informative_post1,\n                     informative_post2) |>\n  pivot_longer(2:4, names_to = \"distribution\", values_to = \"density\") |>\n  separate(distribution, into = c(\"prior_type\", \"distribution\"))\n\nggplot(data = plot_df, aes(x = ps, y = density, colour = prior_type,\n                           linetype = distribution)) +\n  geom_line() +\n  scale_colour_viridis_d(end = 0.9) +\n  theme_minimal() +\n  labs(x = \"p\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nReport:\n\n*In this project, we are looking how three different priors do in representing the distribution of the probability of Nadal winning a point on his serve when playing on clay courts against Djokovic. To answer this, I graphed the three priors and then updated the priors with data from the 2020 French Open. I will then explore these distributions as well as their 90% confidence intervals and means. \n\n*To create the noninformative prior, I just used a beta distribution with alpha and beta equal to 1. To create the prior for the observed data, I created a target mean of the probability from the data and ran through different alphas and betas to get yield a mean of .4 and a vairaince closest to the target. \nTo create the prior for based on the sports announcer prediction we used their probability they claim in correct and run through combinations of alpha and ks to get the probability. Since they are \"almost sure\" that Nadal wins no less than 70% of the points I used a target_prob of .02 because it's not likely, but not impossible. I used a gamma distribution to find this probability.For these priors, we made the assumptions that the matches were all independent, so Nadal doing well or not well before didn't affect how he did at the 2020 French Open.\n\n*Graphs and intervals are above.\n\n*All of the posteriors are a bit different because their priors were all different and we added the same values to each of them. If I were to pick one, I would pick the post1 which is based on the prior of the other observed match. The distribution did not move too much from it's prior and has the narrowest interval. Since the distribution didn't move form the prior to the posterior, the variance will be lower than the other two posteriors. \n\n*In this mini-project, I found, with some difference depending on the prior used, the probability of Nadal winning a point when he serves againt Djokovic on clay courts is between around .58 and .74.\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}